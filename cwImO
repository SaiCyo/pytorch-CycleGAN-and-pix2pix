diff --git a/.coafile b/.coafile
new file mode 100644
index 0000000..76c559e
--- /dev/null
+++ b/.coafile
@@ -0,0 +1,14 @@
+# Generated by coala-quickstart on 16 Jan 2018.
+[default]
+bears = InvalidLinkBear, FilenameBear, coalaBear
+files = **.yml, **.py, **.md
+ignore = 
+[markdown]
+bears = MarkdownBear, LineLengthBear
+files = **.md
+[python]
+bears = PycodestyleBear
+files = **.py
+[yaml]
+bears = YAMLLintBear, LineLengthBear
+files = **.yml
diff --git a/coala-ci.log b/coala-ci.log
new file mode 100644
index 0000000..6ace29f
--- /dev/null
+++ b/coala-ci.log
@@ -0,0 +1,1805 @@
+Executing section Default...
+
+.travis.yml
+|  12| ••#•Create•two•diff•files,•and•upload•to•https://clbin.com
+|    | [NORMAL] InvalidLinkBear:
+|    | Broken link - unable to connect to https://clbin.com (HTTP Error: 404)
+
+.travis.yml
+|  17| ••-•cat•sans-whitespace.diff•|•curl•-F•'clbin=<-'•https://clbin.com
+|    | [NORMAL] InvalidLinkBear:
+|    | Broken link - unable to connect to https://clbin.com (HTTP Error: 404)
+
+.travis.yml
+|  19| ••-•cat•with-whitespace.diff•|•curl•-F•'clbin=<-'•https://clbin.com
+|    | [NORMAL] InvalidLinkBear:
+|    | Broken link - unable to connect to https://clbin.com (HTTP Error: 404)
+
+.travis.yml
+|  20| ••#•Upload•logs•to•https://clbin.com
+|    | [NORMAL] InvalidLinkBear:
+|    | Broken link - unable to connect to https://clbin.com (HTTP Error: 404)
+
+.travis.yml
+|  21| ••-•cat•coala-ci.log•|•curl•-F•'clbin=<-'•https://clbin.com
+|    | [NORMAL] InvalidLinkBear:
+|    | Broken link - unable to connect to https://clbin.com (HTTP Error: 404)
+|    | [NORMAL] FilenameBear:
+|    | Filename does not follow snake naming-convention.
+|----|    | a/datasets/combine_A_and_B.py
+|    |++++| b/datasets/combine_a_and_b.py
+
+README.md
+| 188| -•`horse2zebra`:•939•horse•images•and•1177•zebra•images•downloaded•from•[ImageNet](http://www.image-net.org)•using•keywords•`wild•horse`•and•`zebra`
+|    | [MAJOR] InvalidLinkBear:
+|    | Broken link - unable to connect to http://www.image-net.org
+
+README.md
+| 189| -•`apple2orange`:•996•apple•images•and•1020•orange•images•downloaded•from•[ImageNet](http://www.image-net.org)•using•keywords•`apple`•and•`navel•orange`.
+|    | [MAJOR] InvalidLinkBear:
+|    | Broken link - unable to connect to http://www.image-net.org
+Executing section markdown...
+|    | [NORMAL] MarkdownBear:
+|    | The text does not comply to the set style.
+|----|    | /app/README.md
+|    |++++| /app/README.md
+|  10|  10| 
+|  11|  11| Check out the original [CycleGAN Torch](https://github.com/junyanz/CycleGAN) and [pix2pix Torch](https://github.com/phillipi/pix2pix) code if you would like to reproduce the exact same results as in the papers.
+|  12|  12| 
+|  13|    |-
+|  14|    |-#### CycleGAN: [[Project]](https://junyanz.github.io/CycleGAN/) [[Paper]](https://arxiv.org/pdf/1703.10593.pdf) [[Torch]](https://github.com/junyanz/CycleGAN)
+|    |  13|+#### CycleGAN: [\[Project\]](https://junyanz.github.io/CycleGAN/) [\[Paper\]](https://arxiv.org/pdf/1703.10593.pdf) [\[Torch\]](https://github.com/junyanz/CycleGAN)
+|    |  14|+
+|  15|  15| <img src="https://junyanz.github.io/CycleGAN/images/teaser_high_res.jpg" width="900"/>
+|  16|  16| 
+|  17|  17| #### Pix2pix:  [[Project]](https://phillipi.github.io/pix2pix/) [[Paper]](https://arxiv.org/pdf/1611.07004v1.pdf) [[Torch]](https://github.com/phillipi/pix2pix)
+|    | [NORMAL] MarkdownBear:
+|    | The text does not comply to the set style.
+|----|    | /app/README.md
+|    |++++| /app/README.md
+|  14|  14| #### CycleGAN: [[Project]](https://junyanz.github.io/CycleGAN/) [[Paper]](https://arxiv.org/pdf/1703.10593.pdf) [[Torch]](https://github.com/junyanz/CycleGAN)
+|  15|  15| <img src="https://junyanz.github.io/CycleGAN/images/teaser_high_res.jpg" width="900"/>
+|  16|  16| 
+|  17|    |-#### Pix2pix:  [[Project]](https://phillipi.github.io/pix2pix/) [[Paper]](https://arxiv.org/pdf/1611.07004v1.pdf) [[Torch]](https://github.com/phillipi/pix2pix)
+|    |  17|+#### Pix2pix:  [\[Project\]](https://phillipi.github.io/pix2pix/) [\[Paper\]](https://arxiv.org/pdf/1611.07004v1.pdf) [\[Torch\]](https://github.com/phillipi/pix2pix)
+|  18|  18| 
+|  19|  19| <img src="https://phillipi.github.io/pix2pix/images/teaser_v3.png" width="900px"/>
+|  20|  20| 
+|    | [NORMAL] MarkdownBear:
+|    | The text does not comply to the set style.
+|----|    | /app/README.md
+|    |++++| /app/README.md
+|  18|  18| 
+|  19|  19| <img src="https://phillipi.github.io/pix2pix/images/teaser_v3.png" width="900px"/>
+|  20|  20| 
+|  21|    |-#### [[EdgesCats Demo]](https://affinelayer.com/pixsrv/)  [[pix2pix-tensorflow]](https://github.com/affinelayer/pix2pix-tensorflow)   
+|    |  21|+#### [\[EdgesCats Demo\]](https://affinelayer.com/pixsrv/)  [\[pix2pix-tensorflow\]](https://github.com/affinelayer/pix2pix-tensorflow)
+|    |  22|+
+|  22|  23| Written by [Christopher Hesse](https://twitter.com/christophrhesse)  
+|  23|  24| 
+|  24|  25| <img src='imgs/edges2cats.jpg' width="600px"/>
+|    | [NORMAL] MarkdownBear:
+|    | The text does not comply to the set style.
+|----|    | /app/README.md
+|    |++++| /app/README.md
+|  27|  27| 
+|  28|  28| Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks  
+|  29|  29| [Jun-Yan Zhu](https://people.eecs.berkeley.edu/~junyanz/)\*,  [Taesung Park](https://taesung.me/)\*, [Phillip Isola](https://people.eecs.berkeley.edu/~isola/), [Alexei A. Efros](https://people.eecs.berkeley.edu/~efros)  
+|  30|    |-In arxiv, 2017. (* equal contributions)  
+|  31|    |-
+|    |  30|+In arxiv, 2017. (\* equal contributions)  
+|  32|  31| 
+|  33|  32| Image-to-Image Translation with Conditional Adversarial Networks  
+|  34|  33| [Phillip Isola](https://people.eecs.berkeley.edu/~isola), [Jun-Yan Zhu](https://people.eecs.berkeley.edu/~junyanz), [Tinghui Zhou](https://people.eecs.berkeley.edu/~tinghuiz), [Alexei A. Efros](https://people.eecs.berkeley.edu/~efros)   
+|    | [NORMAL] MarkdownBear:
+|    | The text does not comply to the set style.
+|----|    | /app/README.md
+|    |++++| /app/README.md
+|  31|  31| 
+|  32|  32| 
+|  33|  33| Image-to-Image Translation with Conditional Adversarial Networks  
+|  34|    |-[Phillip Isola](https://people.eecs.berkeley.edu/~isola), [Jun-Yan Zhu](https://people.eecs.berkeley.edu/~junyanz), [Tinghui Zhou](https://people.eecs.berkeley.edu/~tinghuiz), [Alexei A. Efros](https://people.eecs.berkeley.edu/~efros)   
+|    |  34|+[Phillip Isola](https://people.eecs.berkeley.edu/~isola), [Jun-Yan Zhu](https://people.eecs.berkeley.edu/~junyanz), [Tinghui Zhou](https://people.eecs.berkeley.edu/~tinghuiz), [Alexei A. Efros](https://people.eecs.berkeley.edu/~efros)  
+|  35|  35| In CVPR 2017.
+|  36|  36| 
+|  37|  37| ## Other implementations:
+|    | [NORMAL] MarkdownBear:
+|    | The text does not comply to the set style.
+|----|    | /app/README.md
+|    |++++| /app/README.md
+|  35|  35| In CVPR 2017.
+|  36|  36| 
+|  37|  37| ## Other implementations:
+|    |  38|+
+|  38|  39| ### CycleGAN
+|    |  40|+
+|  39|  41| <p><a href="https://github.com/leehomyc/cyclegan-1"> [Tensorflow]</a> (by Harry Yang),
+|  40|  42| <a href="https://github.com/architrathore/CycleGAN/">[Tensorflow]</a> (by Archit Rathore),
+|  41|  43| <a href="https://github.com/vanhuyz/CycleGAN-TensorFlow">[Tensorflow]</a> (by Van Huy),
+|    | [NORMAL] MarkdownBear:
+|    | The text does not comply to the set style.
+|----|    | /app/README.md
+|    |++++| /app/README.md
+|  49|  49| </ul>
+|  50|  50| 
+|  51|  51| ### pix2pix
+|    |  52|+
+|  52|  53| <p><a href="https://github.com/affinelayer/pix2pix-tensorflow"> [Tensorflow]</a> (by Christopher Hesse),
+|  53|  54| <a href="https://github.com/Eyyub/tensorflow-pix2pix">[Tensorflow]</a> (by Eyyüb Sariu),
+|  54|  55| <a href="https://github.com/datitran/face2face-demo"> [Tensorflow (face2face)]</a> (by Dat Tran),
+|    | [NORMAL] MarkdownBear:
+|    | The text does not comply to the set style.
+|----|    | /app/README.md
+|    |++++| /app/README.md
+|  61|  61| </ul>
+|  62|  62| 
+|  63|  63| ## Prerequisites
+|    |  64|+
+|  64|  65| - Linux or macOS
+|  65|  66| - Python 2 or 3
+|  66|  67| - CPU or NVIDIA GPU + CUDA CuDNN
+|    | [NORMAL] MarkdownBear:
+|    | The text does not comply to the set style.
+|----|    | /app/README.md
+|    |++++| /app/README.md
+|  66|  66| - CPU or NVIDIA GPU + CUDA CuDNN
+|  67|  67| 
+|  68|  68| ## Getting Started
+|    |  69|+
+|  69|  70| ### Installation
+|  70|    |-- Install PyTorch and dependencies from http://pytorch.org
+|    |  71|+
+|    |  72|+- Install PyTorch and dependencies from <http://pytorch.org>
+|  71|  73| - Install Torch vision from the source.
+|    |  74|+
+|  72|  75| ```bash
+|  73|  76| git clone https://github.com/pytorch/vision
+|  74|  77| cd vision
+|    | [NORMAL] MarkdownBear:
+|    | The text does not comply to the set style.
+|----|    | /app/README.md
+|    |++++| /app/README.md
+|  74|  74| cd vision
+|  75|  75| python setup.py install
+|  76|  76| ```
+|    |  77|+
+|  77|  78| - Install python libraries [visdom](https://github.com/facebookresearch/visdom) and [dominate](https://github.com/Knio/dominate).
+|    |  79|+
+|  78|  80| ```bash
+|  79|  81| pip install visdom
+|  80|  82| pip install dominate
+|    | [NORMAL] MarkdownBear:
+|    | The text does not comply to the set style.
+|----|    | /app/README.md
+|    |++++| /app/README.md
+|  79|  79| pip install visdom
+|  80|  80| pip install dominate
+|  81|  81| ```
+|    |  82|+
+|  82|  83| - Clone this repo:
+|    |  84|+
+|  83|  85| ```bash
+|  84|  86| git clone https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix
+|  85|  87| cd pytorch-CycleGAN-and-pix2pix
+|    | [NORMAL] MarkdownBear:
+|    | The text does not comply to the set style.
+|----|    | /app/README.md
+|    |++++| /app/README.md
+|  86|  86| ```
+|  87|  87| 
+|  88|  88| ### CycleGAN train/test
+|    |  89|+
+|  89|  90| - Download a CycleGAN dataset (e.g. maps):
+|    |  91|+
+|  90|  92| ```bash
+|  91|  93| bash ./datasets/download_cyclegan_dataset.sh maps
+|  92|  94| ```
+|    | [NORMAL] MarkdownBear:
+|    | The text does not comply to the set style.
+|----|    | /app/README.md
+|    |++++| /app/README.md
+|  90|  90| ```bash
+|  91|  91| bash ./datasets/download_cyclegan_dataset.sh maps
+|  92|  92| ```
+|    |  93|+
+|  93|  94| - Train a model:
+|    |  95|+
+|  94|  96| ```bash
+|  95|  97| #!./scripts/train_cyclegan.sh
+|  96|  98| python train.py --dataroot ./datasets/maps --name maps_cyclegan --model cycle_gan --no_dropout
+|    | [NORMAL] MarkdownBear:
+|    | The text does not comply to the set style.
+|----|    | /app/README.md
+|    |++++| /app/README.md
+|  95|  95| #!./scripts/train_cyclegan.sh
+|  96|  96| python train.py --dataroot ./datasets/maps --name maps_cyclegan --model cycle_gan --no_dropout
+|  97|  97| ```
+|  98|    |-- To view training results and loss plots, run `python -m visdom.server` and click the URL http://localhost:8097. To see more intermediate results, check out `./checkpoints/maps_cyclegan/web/index.html`
+|    |  98|+
+|    |  99|+- To view training results and loss plots, run `python -m visdom.server` and click the URL <http://localhost:8097>. To see more intermediate results, check out `./checkpoints/maps_cyclegan/web/index.html`
+|  99| 100| - Test the model:
+|    | 101|+
+| 100| 102| ```bash
+| 101| 103| #!./scripts/test_cyclegan.sh
+| 102| 104| python test.py --dataroot ./datasets/maps --name maps_cyclegan --model cycle_gan --phase test --no_dropout
+|    | [NORMAL] MarkdownBear:
+|    | The text does not comply to the set style.
+|----|    | /app/README.md
+|    |++++| /app/README.md
+| 101| 101| #!./scripts/test_cyclegan.sh
+| 102| 102| python test.py --dataroot ./datasets/maps --name maps_cyclegan --model cycle_gan --phase test --no_dropout
+| 103| 103| ```
+|    | 104|+
+| 104| 105| The test results will be saved to a html file here: `./results/maps_cyclegan/latest_test/index.html`.
+| 105| 106| 
+| 106| 107| ### pix2pix train/test
+|    | [NORMAL] MarkdownBear:
+|    | The text does not comply to the set style.
+|----|    | /app/README.md
+|    |++++| /app/README.md
+| 104| 104| The test results will be saved to a html file here: `./results/maps_cyclegan/latest_test/index.html`.
+| 105| 105| 
+| 106| 106| ### pix2pix train/test
+|    | 107|+
+| 107| 108| - Download a pix2pix dataset (e.g.facades):
+|    | 109|+
+| 108| 110| ```bash
+| 109| 111| bash ./datasets/download_pix2pix_dataset.sh facades
+| 110| 112| ```
+|    | [NORMAL] MarkdownBear:
+|    | The text does not comply to the set style.
+|----|    | /app/README.md
+|    |++++| /app/README.md
+| 108| 108| ```bash
+| 109| 109| bash ./datasets/download_pix2pix_dataset.sh facades
+| 110| 110| ```
+|    | 111|+
+| 111| 112| - Train a model:
+|    | 113|+
+| 112| 114| ```bash
+| 113| 115| #!./scripts/train_pix2pix.sh
+| 114| 116| python train.py --dataroot ./datasets/facades --name facades_pix2pix --model pix2pix --which_model_netG unet_256 --which_direction BtoA --lambda_A 100 --dataset_mode aligned --no_lsgan --norm batch --pool_size 0
+|    | [NORMAL] MarkdownBear:
+|    | The text does not comply to the set style.
+|----|    | /app/README.md
+|    |++++| /app/README.md
+| 113| 113| #!./scripts/train_pix2pix.sh
+| 114| 114| python train.py --dataroot ./datasets/facades --name facades_pix2pix --model pix2pix --which_model_netG unet_256 --which_direction BtoA --lambda_A 100 --dataset_mode aligned --no_lsgan --norm batch --pool_size 0
+| 115| 115| ```
+| 116|    |-- To view training results and loss plots, run `python -m visdom.server` and click the URL http://localhost:8097. To see more intermediate results, check out  `./checkpoints/facades_pix2pix/web/index.html`
+|    | 116|+
+|    | 117|+- To view training results and loss plots, run `python -m visdom.server` and click the URL <http://localhost:8097>. To see more intermediate results, check out  `./checkpoints/facades_pix2pix/web/index.html`
+| 117| 118| - Test the model (`bash ./scripts/test_pix2pix.sh`):
+|    | 119|+
+| 118| 120| ```bash
+| 119| 121| #!./scripts/test_pix2pix.sh
+| 120| 122| python test.py --dataroot ./datasets/facades --name facades_pix2pix --model pix2pix --which_model_netG unet_256 --which_direction BtoA --dataset_mode aligned --norm batch
+|    | [NORMAL] MarkdownBear:
+|    | The text does not comply to the set style.
+|----|    | /app/README.md
+|    |++++| /app/README.md
+| 119| 119| #!./scripts/test_pix2pix.sh
+| 120| 120| python test.py --dataroot ./datasets/facades --name facades_pix2pix --model pix2pix --which_model_netG unet_256 --which_direction BtoA --dataset_mode aligned --norm batch
+| 121| 121| ```
+|    | 122|+
+| 122| 123| The test results will be saved to a html file here: `./results/facades_pix2pix/latest_val/index.html`.
+| 123| 124| 
+| 124| 125| More example scripts can be found at `scripts` directory.
+|    | [NORMAL] MarkdownBear:
+|    | The text does not comply to the set style.
+|----|    | /app/README.md
+|    |++++| /app/README.md
+| 124| 124| More example scripts can be found at `scripts` directory.
+| 125| 125| 
+| 126| 126| ### Apply a pre-trained model (CycleGAN)
+|    | 127|+
+| 127| 128| - You can download a pretrained model (e.g. horse2zebra) with the following script:
+|    | 129|+
+| 128| 130| ```bash
+| 129| 131| bash pretrained_models/download_cyclegan_model.sh horse2zebra
+| 130| 132| ```
+|    | [NORMAL] MarkdownBear:
+|    | The text does not comply to the set style.
+|----|    | /app/README.md
+|    |++++| /app/README.md
+| 128| 128| ```bash
+| 129| 129| bash pretrained_models/download_cyclegan_model.sh horse2zebra
+| 130| 130| ```
+|    | 131|+
+| 131| 132| The pretrained model is saved at `./checkpoints/{name}_pretrained/latest_net_G.pth`.
+|    | 133|+
+| 132| 134| - To test the model, you also need to download the  horse2zebra dataset:
+|    | 135|+
+| 133| 136| ```bash
+| 134| 137| bash ./datasets/download_cyclegan_dataset.sh horse2zebra
+| 135| 138| ```
+|    | [NORMAL] MarkdownBear:
+|    | The text does not comply to the set style.
+|----|    | /app/README.md
+|    |++++| /app/README.md
+| 135| 135| ```
+| 136| 136| 
+| 137| 137| - Then generate the results using
+|    | 138|+
+| 138| 139| ```bash
+| 139| 140| python test.py --dataroot datasets/horse2zebra/testA --checkpoints_dir ./checkpoints/ --name horse2zebra_pretrained --no_dropout --model test --dataset_mode single --loadSize 256
+| 140| 141| ```
+|    | [NORMAL] MarkdownBear:
+|    | The text does not comply to the set style.
+|----|    | /app/README.md
+|    |++++| /app/README.md
+| 138| 138| ```bash
+| 139| 139| python test.py --dataroot datasets/horse2zebra/testA --checkpoints_dir ./checkpoints/ --name horse2zebra_pretrained --no_dropout --model test --dataset_mode single --loadSize 256
+| 140| 140| ```
+|    | 141|+
+| 141| 142| The results will be saved at `./results/`. Use `--results_dir {directory_path_to_save_result}` to specify the results directory.
+|    | 143|+
+| 142| 144| - Note: The models trained using Torch and PyTorch produce slightly different results, although we were not able to decide which result is better. If you would like to reproduce the same results in our paper, we recommend using the pretrained models in the Torch codebase.
+| 143| 145| 
+| 144| 146| - If you would like to apply a pre-trained model to a collection of input images (rather than image pairs), please use `--dataset_mode single` and `--model test` options. Here is a script to apply a model to Facade label maps (stored in the directory `facades/testB`).
+|    | [NORMAL] MarkdownBear:
+|    | The text does not comply to the set style.
+|----|    | /app/README.md
+|    |++++| /app/README.md
+| 142| 142| - Note: The models trained using Torch and PyTorch produce slightly different results, although we were not able to decide which result is better. If you would like to reproduce the same results in our paper, we recommend using the pretrained models in the Torch codebase.
+| 143| 143| 
+| 144| 144| - If you would like to apply a pre-trained model to a collection of input images (rather than image pairs), please use `--dataset_mode single` and `--model test` options. Here is a script to apply a model to Facade label maps (stored in the directory `facades/testB`).
+| 145|    |-``` bash
+|    | 145|+
+|    | 146|+```bash
+| 146| 147| #!./scripts/test_single.sh
+| 147| 148| python test.py --dataroot ./datasets/facades/testB/ --name {your_trained_model_name} --model test --dataset_mode single
+| 148| 149| ```
+|    | [NORMAL] MarkdownBear:
+|    | The text does not comply to the set style.
+|----|    | /app/README.md
+|    |++++| /app/README.md
+| 146| 146| #!./scripts/test_single.sh
+| 147| 147| python test.py --dataroot ./datasets/facades/testB/ --name {your_trained_model_name} --model test --dataset_mode single
+| 148| 148| ```
+|    | 149|+
+| 149| 150| You might want to specify `--which_model_netG` to match the generator architecture of the trained model.
+| 150| 151| 
+| 151| 152| ### Apply a pre-trained model (pix2pix)
+|    | [NORMAL] MarkdownBear:
+|    | The text does not comply to the set style.
+|----|    | /app/README.md
+|    |++++| /app/README.md
+| 153| 153| Download a pre-trained model with `./pretrained_models/download_pix2pix_model.sh`.
+| 154| 154| 
+| 155| 155| - For example, if you would like to download label2photo model on the Facades dataset,
+|    | 156|+
+| 156| 157| ```bash
+| 157| 158| bash pretrained_models/download_pix2pix_model.sh facades_label2photo
+| 158| 159| ```
+|    | [NORMAL] MarkdownBear:
+|    | The text does not comply to the set style.
+|----|    | /app/README.md
+|    |++++| /app/README.md
+| 158| 158| ```
+| 159| 159| 
+| 160| 160| - Download the pix2pix facades datasets
+|    | 161|+
+| 161| 162| ```bash
+| 162| 163| bash ./datasets/download_pix2pix_dataset.sh facades
+| 163| 164| ```
+|    | [NORMAL] MarkdownBear:
+|    | The text does not comply to the set style.
+|----|    | /app/README.md
+|    |++++| /app/README.md
+| 161| 161| ```bash
+| 162| 162| bash ./datasets/download_pix2pix_dataset.sh facades
+| 163| 163| ```
+|    | 164|+
+| 164| 165| - Then generate the results using
+|    | 166|+
+| 165| 167| ```bash
+| 166| 168| python test.py --dataroot ./datasets/facades/ --which_direction BtoA --model pix2pix --name facades_label2photo_pretrained --dataset_mode aligned --which_model_netG unet_256 --norm batch
+| 167| 169| ```
+|    | [NORMAL] MarkdownBear:
+|    | The text does not comply to the set style.
+|----|    | /app/README.md
+|    |++++| /app/README.md
+| 165| 165| ```bash
+| 166| 166| python test.py --dataroot ./datasets/facades/ --which_direction BtoA --model pix2pix --name facades_label2photo_pretrained --dataset_mode aligned --which_model_netG unet_256 --norm batch
+| 167| 167| ```
+|    | 168|+
+| 168| 169| Note that we specified `--which_direction BtoA` as Facades dataset's A to B direction is photos to labels.
+| 169| 170| 
+| 170| 171| - See a list of currently available models at `bash pretrained_models/download_pix2pix_model.sh`
+|    | [NORMAL] MarkdownBear:
+|    | The text does not comply to the set style.
+|----|    | /app/README.md
+|    |++++| /app/README.md
+| 170| 170| - See a list of currently available models at `bash pretrained_models/download_pix2pix_model.sh`
+| 171| 171| 
+| 172| 172| ## Training/test Details
+|    | 173|+
+| 173| 174| - Flags: see `options/train_options.py` and `options/base_options.py` for all the training flags; see `options/test_options.py` and `options/base_options.py` for all the test flags.
+| 174| 175| - CPU/GPU (default `--gpu_ids 0`): set`--gpu_ids -1` to use CPU mode; set `--gpu_ids 0,1,2` for multi-GPU mode. You need a large batch size (e.g. `--batchSize 32`) to benefit from multiple GPUs.  
+| 175| 176| - Visualization: during training, the current results can be viewed using two methods. First, if you set `--display_id` > 0, the results and loss plot will appear on a local graphics web server launched by [visdom](https://github.com/facebookresearch/visdom). To do this, you should have `visdom` installed and a server running by the command `python -m visdom.server`. The default server URL is `http://localhost:8097`. `display_id` corresponds to the window ID that is displayed on the `visdom` server. The `visdom` display functionality is turned on by default. To avoid the extra overhead of communicating with `visdom` set `--display_id 0`. Second, the intermediate results are saved to `[opt.checkpoints_dir]/[opt.name]/web/` as an HTML file. To avoid this, set `--no_html`.
+|    | [NORMAL] MarkdownBear:
+|    | The text does not comply to the set style.
+|----|    | /app/README.md
+|    |++++| /app/README.md
+| 176| 176| - Preprocessing: images can be resized and cropped in different ways using `--resize_or_crop` option. The default option `'resize_and_crop'` resizes the image to be of size `(opt.loadSize, opt.loadSize)` and does a random crop of size `(opt.fineSize, opt.fineSize)`. `'crop'` skips the resizing step and only performs random cropping. `'scale_width'` resizes the image to have width `opt.fineSize` while keeping the aspect ratio. `'scale_width_and_crop'` first resizes the image to have width `opt.loadSize` and then does random cropping of size `(opt.fineSize, opt.fineSize)`.
+| 177| 177| - Fine-tuning/Resume training: to fine-tune a pre-trained model, or resume the previous training, use the `--continue_train` flag. The program will then load the model based on `which_epoch`. By default, the program will initialize the epoch count as 1. Set `--epoch_count <int>` to specify a different starting epoch count.
+| 178| 178| 
+| 179|    |-
+| 180| 179| ### CycleGAN Datasets
+|    | 180|+
+| 181| 181| Download the CycleGAN datasets using the following script. Some of the datasets are collected by other researchers. Please cite their papers if you use the data.
+|    | 182|+
+| 182| 183| ```bash
+| 183| 184| bash ./datasets/download_cyclegan_dataset.sh dataset_name
+| 184| 185| ```
+|    | [NORMAL] MarkdownBear:
+|    | The text does not comply to the set style.
+|----|    | /app/README.md
+|    |++++| /app/README.md
+| 182| 182| ```bash
+| 183| 183| bash ./datasets/download_cyclegan_dataset.sh dataset_name
+| 184| 184| ```
+| 185|    |-- `facades`: 400 images from the [CMP Facades dataset](http://cmp.felk.cvut.cz/~tylecr1/facade). [[Citation](datasets/bibtex/facades.tex)]
+| 186|    |-- `cityscapes`: 2975 images from the [Cityscapes training set](https://www.cityscapes-dataset.com). [[Citation](datasets/bibtex/cityscapes.tex)]
+|    | 185|+
+|    | 186|+- `facades`: 400 images from the [CMP Facades dataset](http://cmp.felk.cvut.cz/~tylecr1/facade). \[[Citation](datasets/bibtex/facades.tex)]
+|    | 187|+- `cityscapes`: 2975 images from the [Cityscapes training set](https://www.cityscapes-dataset.com). \[[Citation](datasets/bibtex/cityscapes.tex)]
+| 187| 188| - `maps`: 1096 training images scraped from Google Maps.
+| 188| 189| - `horse2zebra`: 939 horse images and 1177 zebra images downloaded from [ImageNet](http://www.image-net.org) using keywords `wild horse` and `zebra`
+| 189| 190| - `apple2orange`: 996 apple images and 1020 orange images downloaded from [ImageNet](http://www.image-net.org) using keywords `apple` and `navel orange`.
+|    | [NORMAL] MarkdownBear:
+|    | The text does not comply to the set style.
+|----|    | /app/README.md
+|    |++++| /app/README.md
+| 196| 196| You should **not** expect our method to work on just any random combination of input and output datasets (e.g. `cats<->keyboards`). From our experiments, we find it works better if two datasets share similar visual content. For example, `landscape painting<->landscape photographs` works much better than `portrait painting <-> landscape photographs`. `zebras<->horses` achieves compelling results while `cats<->dogs` completely fails.
+| 197| 197| 
+| 198| 198| ### pix2pix datasets
+|    | 199|+
+| 199| 200| Download the pix2pix datasets using the following script. Some of the datasets are collected by other researchers. Please cite their papers if you use the data.
+|    | 201|+
+| 200| 202| ```bash
+| 201| 203| bash ./datasets/download_pix2pix_dataset.sh dataset_name
+| 202| 204| ```
+|    | [NORMAL] MarkdownBear:
+|    | The text does not comply to the set style.
+|----|    | /app/README.md
+|    |++++| /app/README.md
+| 200| 200| ```bash
+| 201| 201| bash ./datasets/download_pix2pix_dataset.sh dataset_name
+| 202| 202| ```
+| 203|    |-- `facades`: 400 images from [CMP Facades dataset](http://cmp.felk.cvut.cz/~tylecr1/facade). [[Citation](datasets/bibtex/facades.tex)]
+| 204|    |-- `cityscapes`: 2975 images from the [Cityscapes training set](https://www.cityscapes-dataset.com). [[Citation](datasets/bibtex/cityscapes.tex)]
+|    | 203|+
+|    | 204|+- `facades`: 400 images from [CMP Facades dataset](http://cmp.felk.cvut.cz/~tylecr1/facade). \[[Citation](datasets/bibtex/facades.tex)]
+|    | 205|+- `cityscapes`: 2975 images from the [Cityscapes training set](https://www.cityscapes-dataset.com). \[[Citation](datasets/bibtex/cityscapes.tex)]
+| 205| 206| - `maps`: 1096 training images scraped from Google Maps
+| 206|    |-- `edges2shoes`: 50k training images from [UT Zappos50K dataset](http://vision.cs.utexas.edu/projects/finegrained/utzap50k). Edges are computed by [HED](https://github.com/s9xie/hed) edge detector + post-processing. [[Citation](datasets/bibtex/shoes.tex)]
+| 207|    |-- `edges2handbags`: 137K Amazon Handbag images from [iGAN project](https://github.com/junyanz/iGAN). Edges are computed by [HED](https://github.com/s9xie/hed) edge detector + post-processing. [[Citation](datasets/bibtex/handbags.tex)]
+|    | 207|+- `edges2shoes`: 50k training images from [UT Zappos50K dataset](http://vision.cs.utexas.edu/projects/finegrained/utzap50k). Edges are computed by [HED](https://github.com/s9xie/hed) edge detector + post-processing. \[[Citation](datasets/bibtex/shoes.tex)]
+|    | 208|+- `edges2handbags`: 137K Amazon Handbag images from [iGAN project](https://github.com/junyanz/iGAN). Edges are computed by [HED](https://github.com/s9xie/hed) edge detector + post-processing. \[[Citation](datasets/bibtex/handbags.tex)]
+| 208| 209| 
+| 209| 210| We provide a python script to generate pix2pix training data in the form of pairs of images {A,B}, where A and B are two different depictions of the same underlying scene. For example, these might be pairs {label map, photo} or {bw image, color image}. Then we can learn to translate A to B or B to A:
+| 210| 211| 
+|    | [NORMAL] MarkdownBear:
+|    | The text does not comply to the set style.
+|----|    | /app/README.md
+|    |++++| /app/README.md
+| 213| 213| Corresponding images in a pair {A,B} must be the same size and have the same filename, e.g., `/path/to/data/A/train/1.jpg` is considered to correspond to `/path/to/data/B/train/1.jpg`.
+| 214| 214| 
+| 215| 215| Once the data is formatted this way, call:
+|    | 216|+
+| 216| 217| ```bash
+| 217| 218| python datasets/combine_A_and_B.py --fold_A /path/to/data/A --fold_B /path/to/data/B --fold_AB /path/to/data
+| 218| 219| ```
+|    | [NORMAL] MarkdownBear:
+|    | The text does not comply to the set style.
+|----|    | /app/README.md
+|    |++++| /app/README.md
+| 220| 220| This will combine each pair of images (A,B) into a single image file, ready for training.
+| 221| 221| 
+| 222| 222| ## Citation
+|    | 223|+
+| 223| 224| If you use this code for your research, please cite our papers.
+|    | 225|+
+| 224| 226| ```
+| 225| 227| @article{CycleGAN2017,
+| 226| 228|   title={Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks},
+|    | [NORMAL] MarkdownBear:
+|    | The text does not comply to the set style.
+|----|    | /app/README.md
+|    |++++| /app/README.md
+| 238| 238| ```
+| 239| 239| 
+| 240| 240| ## Related Projects
+|    | 241|+
+| 241| 242| [CycleGAN](https://github.com/junyanz/CycleGAN): Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks  
+| 242| 243| [pix2pix](https://github.com/phillipi/pix2pix): Image-to-image translation with conditional adversarial nets  
+| 243| 244| [iGAN](https://github.com/junyanz/iGAN): Interactive Image Generation via Generative Adversarial Networks
+|    | [NORMAL] MarkdownBear:
+|    | The text does not comply to the set style.
+|----|    | /app/README.md
+|    |++++| /app/README.md
+| 243| 243| [iGAN](https://github.com/junyanz/iGAN): Interactive Image Generation via Generative Adversarial Networks
+| 244| 244| 
+| 245| 245| ## Cat Paper Collection
+|    | 246|+
+| 246| 247| If you love cats, and love reading cool graphics, vision, and learning papers, please check out the Cat Paper Collection:  
+| 247|    |-[[Github]](https://github.com/junyanz/CatPapers) [[Webpage]](https://people.eecs.berkeley.edu/~junyanz/cat/cat_papers.html)
+|    | 248|+[\[Github\]](https://github.com/junyanz/CatPapers) [\[Webpage\]](https://people.eecs.berkeley.edu/~junyanz/cat/cat_papers.html)
+| 248| 249| 
+| 249| 250| ## Acknowledgments
+|    | 251|+
+| 250| 252| Code is inspired by [pytorch-DCGAN](https://github.com/pytorch/examples/tree/master/dcgan).
+
+README.md
+|   7| This•is•our•ongoing•PyTorch•implementation•for•both•unpaired•and•paired•image-to-image•translation.
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (99 > 79)
+
+README.md
+|   9| The•code•was•written•by•[Jun-Yan•Zhu](https://github.com/junyanz)•and•[Taesung•Park](https://github.com/taesung89).
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (115 > 79)
+
+README.md
+|  11| Check•out•the•original•[CycleGAN•Torch](https://github.com/junyanz/CycleGAN)•and•[pix2pix•Torch](https://github.com/phillipi/pix2pix)•code•if•you•would•like•to•reproduce•the•exact•same•results•as•in•the•papers.
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (210 > 79)
+
+README.md
+|  14| ####•CycleGAN:•[[Project]](https://junyanz.github.io/CycleGAN/)•[[Paper]](https://arxiv.org/pdf/1703.10593.pdf)•[[Torch]](https://github.com/junyanz/CycleGAN)
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (158 > 79)
+
+README.md
+|  15| <img•src="https://junyanz.github.io/CycleGAN/images/teaser_high_res.jpg"•width="900"/>
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (86 > 79)
+
+README.md
+|  17| ####•Pix2pix:••[[Project]](https://phillipi.github.io/pix2pix/)•[[Paper]](https://arxiv.org/pdf/1611.07004v1.pdf)•[[Torch]](https://github.com/phillipi/pix2pix)
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (160 > 79)
+
+README.md
+|  19| <img•src="https://phillipi.github.io/pix2pix/images/teaser_v3.png"•width="900px"/>
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (82 > 79)
+
+README.md
+|  21| ####•[[EdgesCats•Demo]](https://affinelayer.com/pixsrv/)••[[pix2pix-tensorflow]](https://github.com/affinelayer/pix2pix-tensorflow)•••
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (134 > 79)
+
+README.md
+|  28| Unpaired•Image-to-Image•Translation•using•Cycle-Consistent•Adversarial•Networks••
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (81 > 79)
+
+README.md
+|  29| [Jun-Yan•Zhu](https://people.eecs.berkeley.edu/~junyanz/)\*,••[Taesung•Park](https://taesung.me/)\*,•[Phillip•Isola](https://people.eecs.berkeley.edu/~isola/),•[Alexei•A.•Efros](https://people.eecs.berkeley.edu/~efros)••
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (220 > 79)
+
+README.md
+|  34| [Phillip•Isola](https://people.eecs.berkeley.edu/~isola),•[Jun-Yan•Zhu](https://people.eecs.berkeley.edu/~junyanz),•[Tinghui•Zhou](https://people.eecs.berkeley.edu/~tinghuiz),•[Alexei•A.•Efros](https://people.eecs.berkeley.edu/~efros)•••
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (237 > 79)
+
+README.md
+|  39| <p><a•href="https://github.com/leehomyc/cyclegan-1">•[Tensorflow]</a>•(by•Harry•Yang),
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (86 > 79)
+
+README.md
+|  40| <a•href="https://github.com/architrathore/CycleGAN/">[Tensorflow]</a>•(by•Archit•Rathore),
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (90 > 79)
+
+README.md
+|  41| <a•href="https://github.com/vanhuyz/CycleGAN-TensorFlow">[Tensorflow]</a>•(by•Van•Huy),
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (87 > 79)
+
+README.md
+|  42| <a•href="https://github.com/XHUJOY/CycleGAN-tensorflow">[Tensorflow]</a>•(by•Xiaowei•Hu),
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (89 > 79)
+
+README.md
+|  43| <a•href="https://github.com/LynnHo/CycleGAN-Tensorflow-Simple">•[Tensorflow-simple]</a>•(by•Zhenliang•He),
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (106 > 79)
+
+README.md
+|  44| <a•href="https://github.com/luoxier/CycleGAN_Tensorlayer">•[TensorLayer]</a>•(by•luoxier),
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (90 > 79)
+
+README.md
+|  45| <a•href="https://github.com/Aixile/chainer-cyclegan">[Chainer]</a>•(by•Yanghua•Jin),
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (84 > 79)
+
+README.md
+|  46| <a•href="https://github.com/yunjey/mnist-svhn-transfer">[Minimal•PyTorch]</a>•(by•yunjey),
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (90 > 79)
+
+README.md
+|  47| <a•href="https://github.com/Ldpe2G/DeepLearningForFun/tree/master/Mxnet-Scala/CycleGAN">[Mxnet]</a>•(by•Ldpe2G),
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (112 > 79)
+
+README.md
+|  48| <a•href="https://github.com/tjwei/GANotebooks">[lasagne/keras]</a>•(by•tjwei)</p>
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (81 > 79)
+
+README.md
+|  52| <p><a•href="https://github.com/affinelayer/pix2pix-tensorflow">•[Tensorflow]</a>•(by•Christopher•Hesse),
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (104 > 79)
+
+README.md
+|  53| <a•href="https://github.com/Eyyub/tensorflow-pix2pix">[Tensorflow]</a>•(by•Eyyüb•Sariu),
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (88 > 79)
+
+README.md
+|  54| <a•href="https://github.com/datitran/face2face-demo">•[Tensorflow•(face2face)]</a>•(by•Dat•Tran),
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (97 > 79)
+
+README.md
+|  55| <a•href="https://github.com/awjuliani/Pix2Pix-Film">•[Tensorflow•(film)]</a>•(by•Arthur•Juliani),
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (97 > 79)
+
+README.md
+|  56| <a•href="https://github.com/kaonashi-tyc/zi2zi">[Tensorflow•(zi2zi)]</a>•(by•Yuchen•Tian),
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (90 > 79)
+
+README.md
+|  57| <a•href="https://github.com/pfnet-research/chainer-pix2pix">[Chainer]</a>•(by•mattya),
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (86 > 79)
+
+README.md
+|  58| <a•href="https://github.com/tjwei/GANotebooks">[tf/torch/keras/lasagne]</a>•(by•tjwei),
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (87 > 79)
+
+README.md
+|  59| <a•href="https://github.com/taey16/pix2pixBEGAN.pytorch">[Pytorch]</a>•(by•taey16)
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (82 > 79)
+
+README.md
+|  77| -•Install•python•libraries•[visdom](https://github.com/facebookresearch/visdom)•and•[dominate](https://github.com/Knio/dominate).
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (129 > 79)
+
+README.md
+|  96| python•train.py•--dataroot•./datasets/maps•--name•maps_cyclegan•--model•cycle_gan•--no_dropout
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (94 > 79)
+
+README.md
+|  98| -•To•view•training•results•and•loss•plots,•run•`python•-m•visdom.server`•and•click•the•URL•http://localhost:8097.•To•see•more•intermediate•results,•check•out•`./checkpoints/maps_cyclegan/web/index.html`
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (202 > 79)
+
+README.md
+| 102| python•test.py•--dataroot•./datasets/maps•--name•maps_cyclegan•--model•cycle_gan•--phase•test•--no_dropout
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (106 > 79)
+
+README.md
+| 104| The•test•results•will•be•saved•to•a•html•file•here:•`./results/maps_cyclegan/latest_test/index.html`.
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (101 > 79)
+
+README.md
+| 114| python•train.py•--dataroot•./datasets/facades•--name•facades_pix2pix•--model•pix2pix•--which_model_netG•unet_256•--which_direction•BtoA•--lambda_A•100•--dataset_mode•aligned•--no_lsgan•--norm•batch•--pool_size•0
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (211 > 79)
+
+README.md
+| 116| -•To•view•training•results•and•loss•plots,•run•`python•-m•visdom.server`•and•click•the•URL•http://localhost:8097.•To•see•more•intermediate•results,•check•out••`./checkpoints/facades_pix2pix/web/index.html`
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (205 > 79)
+
+README.md
+| 120| python•test.py•--dataroot•./datasets/facades•--name•facades_pix2pix•--model•pix2pix•--which_model_netG•unet_256•--which_direction•BtoA•--dataset_mode•aligned•--norm•batch
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (170 > 79)
+
+README.md
+| 122| The•test•results•will•be•saved•to•a•html•file•here:•`./results/facades_pix2pix/latest_val/index.html`.
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (102 > 79)
+
+README.md
+| 127| -•You•can•download•a•pretrained•model•(e.g.•horse2zebra)•with•the•following•script:
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (83 > 79)
+
+README.md
+| 131| The•pretrained•model•is•saved•at•`./checkpoints/{name}_pretrained/latest_net_G.pth`.
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (84 > 79)
+
+README.md
+| 139| python•test.py•--dataroot•datasets/horse2zebra/testA•--checkpoints_dir•./checkpoints/•--name•horse2zebra_pretrained•--no_dropout•--model•test•--dataset_mode•single•--loadSize•256
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (178 > 79)
+
+README.md
+| 141| The•results•will•be•saved•at•`./results/`.•Use•`--results_dir•{directory_path_to_save_result}`•to•specify•the•results•directory.
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (128 > 79)
+
+README.md
+| 142| -•Note:•The•models•trained•using•Torch•and•PyTorch•produce•slightly•different•results,•although•we•were•not•able•to•decide•which•result•is•better.•If•you•would•like•to•reproduce•the•same•results•in•our•paper,•we•recommend•using•the•pretrained•models•in•the•Torch•codebase.
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (272 > 79)
+
+README.md
+| 144| -•If•you•would•like•to•apply•a•pre-trained•model•to•a•collection•of•input•images•(rather•than•image•pairs),•please•use•`--dataset_mode•single`•and•`--model•test`•options.•Here•is•a•script•to•apply•a•model•to•Facade•label•maps•(stored•in•the•directory•`facades/testB`).
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (268 > 79)
+
+README.md
+| 147| python•test.py•--dataroot•./datasets/facades/testB/•--name•{your_trained_model_name}•--model•test•--dataset_mode•single
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (119 > 79)
+
+README.md
+| 149| You•might•want•to•specify•`--which_model_netG`•to•match•the•generator•architecture•of•the•trained•model.
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (104 > 79)
+
+README.md
+| 153| Download•a•pre-trained•model•with•`./pretrained_models/download_pix2pix_model.sh`.
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (82 > 79)
+
+README.md
+| 155| -•For•example,•if•you•would•like•to•download•label2photo•model•on•the•Facades•dataset,
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (86 > 79)
+
+README.md
+| 166| python•test.py•--dataroot•./datasets/facades/•--which_direction•BtoA•--model•pix2pix•--name•facades_label2photo_pretrained•--dataset_mode•aligned•--which_model_netG•unet_256•--norm•batch
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (186 > 79)
+
+README.md
+| 168| Note•that•we•specified•`--which_direction•BtoA`•as•Facades•dataset's•A•to•B•direction•is•photos•to•labels.
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (106 > 79)
+
+README.md
+| 170| -•See•a•list•of•currently•available•models•at•`bash•pretrained_models/download_pix2pix_model.sh`
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (96 > 79)
+
+README.md
+| 173| -•Flags:•see•`options/train_options.py`•and•`options/base_options.py`•for•all•the•training•flags;•see•`options/test_options.py`•and•`options/base_options.py`•for•all•the•test•flags.
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (181 > 79)
+
+README.md
+| 174| -•CPU/GPU•(default•`--gpu_ids•0`):•set`--gpu_ids•-1`•to•use•CPU•mode;•set•`--gpu_ids•0,1,2`•for•multi-GPU•mode.•You•need•a•large•batch•size•(e.g.•`--batchSize•32`)•to•benefit•from•multiple•GPUs.••
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (196 > 79)
+
+README.md
+| 175| -•Visualization:•during•training,•the•current•results•can•be•viewed•using•two•methods.•First,•if•you•set•`--display_id`•>•0,•the•results•and•loss•plot•will•appear•on•a•local•graphics•web•server•launched•by•[visdom](https://github.com/facebookresearch/visdom).•To•do•this,•you•should•have•`visdom`•installed•and•a•server•running•by•the•command•`python•-m•visdom.server`.•The•default•server•URL•is•`http://localhost:8097`.•`display_id`•corresponds•to•the•window•ID•that•is•displayed•on•the•`visdom`•server.•The•`visdom`•display•functionality•is•turned•on•by•default.•To•avoid•the•extra•overhead•of•communicating•with•`visdom`•set•`--display_id•0`.•Second,•the•intermediate•results•are•saved•to•`[opt.checkpoints_dir]/[opt.name]/web/`•as•an•HTML•file.•To•avoid•this,•set•`--no_html`.
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (780 > 79)
+
+README.md
+| 176| -•Preprocessing:•images•can•be•resized•and•cropped•in•different•ways•using•`--resize_or_crop`•option.•The•default•option•`'resize_and_crop'`•resizes•the•image•to•be•of•size•`(opt.loadSize,•opt.loadSize)`•and•does•a•random•crop•of•size•`(opt.fineSize,•opt.fineSize)`.•`'crop'`•skips•the•resizing•step•and•only•performs•random•cropping.•`'scale_width'`•resizes•the•image•to•have•width•`opt.fineSize`•while•keeping•the•aspect•ratio.•`'scale_width_and_crop'`•first•resizes•the•image•to•have•width•`opt.loadSize`•and•then•does•random•cropping•of•size•`(opt.fineSize,•opt.fineSize)`.
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (577 > 79)
+
+README.md
+| 177| -•Fine-tuning/Resume•training:•to•fine-tune•a•pre-trained•model,•or•resume•the•previous•training,•use•the•`--continue_train`•flag.•The•program•will•then•load•the•model•based•on•`which_epoch`.•By•default,•the•program•will•initialize•the•epoch•count•as•1.•Set•`--epoch_count•<int>`•to•specify•a•different•starting•epoch•count.
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (324 > 79)
+
+README.md
+| 181| Download•the•CycleGAN•datasets•using•the•following•script.•Some•of•the•datasets•are•collected•by•other•researchers.•Please•cite•their•papers•if•you•use•the•data.
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (161 > 79)
+
+README.md
+| 185| -•`facades`:•400•images•from•the•[CMP•Facades•dataset](http://cmp.felk.cvut.cz/~tylecr1/facade).•[[Citation](datasets/bibtex/facades.tex)]
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (138 > 79)
+
+README.md
+| 186| -•`cityscapes`:•2975•images•from•the•[Cityscapes•training•set](https://www.cityscapes-dataset.com).•[[Citation](datasets/bibtex/cityscapes.tex)]
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (144 > 79)
+
+README.md
+| 188| -•`horse2zebra`:•939•horse•images•and•1177•zebra•images•downloaded•from•[ImageNet](http://www.image-net.org)•using•keywords•`wild•horse`•and•`zebra`
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (148 > 79)
+
+README.md
+| 189| -•`apple2orange`:•996•apple•images•and•1020•orange•images•downloaded•from•[ImageNet](http://www.image-net.org)•using•keywords•`apple`•and•`navel•orange`.
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (153 > 79)
+
+README.md
+| 190| -•`summer2winter_yosemite`:•1273•summer•Yosemite•images•and•854•winter•Yosemite•images•were•downloaded•using•Flickr•API.•See•more•details•in•our•paper.
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (151 > 79)
+
+README.md
+| 191| -•`monet2photo`,•`vangogh2photo`,•`ukiyoe2photo`,•`cezanne2photo`:•The•art•images•were•downloaded•from•[Wikiart](https://www.wikiart.org/).•The•real•photos•are•downloaded•from•Flickr•using•the•combination•of•the•tags•*landscape*•and•*landscapephotography*.•The•training•set•size•of•each•class•is•Monet:1074,•Cezanne:584,•Van•Gogh:401,•Ukiyo-e:1433,•Photographs:6853.
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (366 > 79)
+
+README.md
+| 192| -•`iphone2dslr_flower`:•both•classes•of•images•were•downlaoded•from•Flickr.•The•training•set•size•of•each•class•is•iPhone:1813,•DSLR:3316.•See•more•details•in•our•paper.
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (169 > 79)
+
+README.md
+| 194| To•train•a•model•on•your•own•datasets,•you•need•to•create•a•data•folder•with•two•subdirectories•`trainA`•and•`trainB`•that•contain•images•from•domain•A•and•B.•You•can•test•your•model•on•your•training•set•by•setting•`--phase•train`•in•`test.py`.•You•can•also•create•subdirectories•`testA`•and•`testB`•if•you•have•test•data.
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (322 > 79)
+
+README.md
+| 196| You•should•**not**•expect•our•method•to•work•on•just•any•random•combination•of•input•and•output•datasets•(e.g.•`cats<->keyboards`).•From•our•experiments,•we•find•it•works•better•if•two•datasets•share•similar•visual•content.•For•example,•`landscape•painting<->landscape•photographs`•works•much•better•than•`portrait•painting•<->•landscape•photographs`.•`zebras<->horses`•achieves•compelling•results•while•`cats<->dogs`•completely•fails.
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (435 > 79)
+
+README.md
+| 199| Download•the•pix2pix•datasets•using•the•following•script.•Some•of•the•datasets•are•collected•by•other•researchers.•Please•cite•their•papers•if•you•use•the•data.
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (160 > 79)
+
+README.md
+| 203| -•`facades`:•400•images•from•[CMP•Facades•dataset](http://cmp.felk.cvut.cz/~tylecr1/facade).•[[Citation](datasets/bibtex/facades.tex)]
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (134 > 79)
+
+README.md
+| 204| -•`cityscapes`:•2975•images•from•the•[Cityscapes•training•set](https://www.cityscapes-dataset.com).•[[Citation](datasets/bibtex/cityscapes.tex)]
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (144 > 79)
+
+README.md
+| 206| -•`edges2shoes`:•50k•training•images•from•[UT•Zappos50K•dataset](http://vision.cs.utexas.edu/projects/finegrained/utzap50k).•Edges•are•computed•by•[HED](https://github.com/s9xie/hed)•edge•detector•+•post-processing.•[[Citation](datasets/bibtex/shoes.tex)]
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (255 > 79)
+
+README.md
+| 207| -•`edges2handbags`:•137K•Amazon•Handbag•images•from•[iGAN•project](https://github.com/junyanz/iGAN).•Edges•are•computed•by•[HED](https://github.com/s9xie/hed)•edge•detector•+•post-processing.•[[Citation](datasets/bibtex/handbags.tex)]
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (234 > 79)
+
+README.md
+| 209| We•provide•a•python•script•to•generate•pix2pix•training•data•in•the•form•of•pairs•of•images•{A,B},•where•A•and•B•are•two•different•depictions•of•the•same•underlying•scene.•For•example,•these•might•be•pairs•{label•map,•photo}•or•{bw•image,•color•image}.•Then•we•can•learn•to•translate•A•to•B•or•B•to•A:
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (301 > 79)
+
+README.md
+| 211| Create•folder•`/path/to/data`•with•subfolders•`A`•and•`B`.•`A`•and•`B`•should•each•have•their•own•subfolders•`train`,•`val`,•`test`,•etc.•In•`/path/to/data/A/train`,•put•training•images•in•style•A.•In•`/path/to/data/B/train`,•put•the•corresponding•images•in•style•B.•Repeat•same•for•other•data•splits•(`val`,•`test`,•etc).
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (322 > 79)
+
+README.md
+| 213| Corresponding•images•in•a•pair•{A,B}•must•be•the•same•size•and•have•the•same•filename,•e.g.,•`/path/to/data/A/train/1.jpg`•is•considered•to•correspond•to•`/path/to/data/B/train/1.jpg`.
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (184 > 79)
+
+README.md
+| 217| python•datasets/combine_A_and_B.py•--fold_A•/path/to/data/A•--fold_B•/path/to/data/B•--fold_AB•/path/to/data
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (108 > 79)
+
+README.md
+| 220| This•will•combine•each•pair•of•images•(A,B)•into•a•single•image•file,•ready•for•training.
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (89 > 79)
+
+README.md
+| 226| ••title={Unpaired•Image-to-Image•Translation•using•Cycle-Consistent•Adversarial•Networks},
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (90 > 79)
+
+README.md
+| 227| ••author={Zhu,•Jun-Yan•and•Park,•Taesung•and•Isola,•Phillip•and•Efros,•Alexei•A},
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (81 > 79)
+
+README.md
+| 234| ••author={Isola,•Phillip•and•Zhu,•Jun-Yan•and•Zhou,•Tinghui•and•Efros,•Alexei•A},
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (81 > 79)
+
+README.md
+| 241| [CycleGAN](https://github.com/junyanz/CycleGAN):•Unpaired•Image-to-Image•Translation•using•Cycle-Consistent•Adversarial•Networks••
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (130 > 79)
+
+README.md
+| 242| [pix2pix](https://github.com/phillipi/pix2pix):•Image-to-image•translation•with•conditional•adversarial•nets••
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (110 > 79)
+
+README.md
+| 243| [iGAN](https://github.com/junyanz/iGAN):•Interactive•Image•Generation•via•Generative•Adversarial•Networks
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (105 > 79)
+
+README.md
+| 246| If•you•love•cats,•and•love•reading•cool•graphics,•vision,•and•learning•papers,•please•check•out•the•Cat•Paper•Collection:••
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (123 > 79)
+
+README.md
+| 247| [[Github]](https://github.com/junyanz/CatPapers)•[[Webpage]](https://people.eecs.berkeley.edu/~junyanz/cat/cat_papers.html)
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (123 > 79)
+
+README.md
+| 250| Code•is•inspired•by•[pytorch-DCGAN](https://github.com/pytorch/examples/tree/master/dcgan).
+|    | [NORMAL] LineLengthBear:
+|    | Line is longer than allowed. (91 > 79)
+Executing section python...
+
+data/base_dataset.py
+|   5| class•BaseDataset(data.Dataset):
+|    | [NORMAL] PycodestyleBear (E302):
+|    | E302 expected 2 blank lines, found 1'
+
+data/base_dataset.py
+|  15| def•get_transform(opt):
+|    | [NORMAL] PycodestyleBear (E302):
+|    | E302 expected 2 blank lines, found 1'
+
+data/base_dataset.py
+|  39| def•__scale_width(img,•target_width):
+|    | [NORMAL] PycodestyleBear (E302):
+|    | E302 expected 2 blank lines, found 1'
+
+util/png.py
+|   6| ••••"""•buf:•must•be•bytes•or•a•bytearray•in•py3,•a•regular•string•in•py2.•formatted•RGBRGB...•"""
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (98 > 79 characters)'
+
+util/png.py
+|  31| ••••••chunk(b'IHDR',•struct.pack("!2I5B",•width,•height,•bit_depth,•COLOR_TYPE_RGB,•0,•0,•0))•+
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (95 > 79 characters)'
+
+test.py
+|  20| web_dir•=•os.path.join(opt.results_dir,•opt.name,•'%s_%s'•%•(opt.phase,•opt.which_epoch))
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (89 > 79 characters)'
+
+test.py
+|  21| webpage•=•html.HTML(web_dir,•'Experiment•=•%s,•Phase•=•%s,•Epoch•=•%s'•%•(opt.name,•opt.phase,•opt.which_epoch))
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (112 > 79 characters)'
+
+test.py
+|  31| ••••visualizer.save_images(webpage,•visuals,•img_path,•aspect_ratio=opt.aspect_ratio)
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (85 > 79 characters)'
+
+options/test_options.py
+|   7| ••••••••self.parser.add_argument('--ntest',•type=int,•default=float("inf"),•help='#•of•test•examples.')
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (103 > 79 characters)'
+
+options/test_options.py
+|   8| ••••••••self.parser.add_argument('--results_dir',•type=str,•default='./results/',•help='saves•results•here.')
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (109 > 79 characters)'
+
+options/test_options.py
+|   9| ••••••••self.parser.add_argument('--aspect_ratio',•type=float,•default=1.0,•help='aspect•ratio•of•result•images')
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (113 > 79 characters)'
+
+options/test_options.py
+|  10| ••••••••self.parser.add_argument('--phase',•type=str,•default='test',•help='train,•val,•test,•etc')
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (99 > 79 characters)'
+
+options/test_options.py
+|  11| ••••••••self.parser.add_argument('--which_epoch',•type=str,•default='latest',•help='which•epoch•to•load?•set•to•latest•to•use•latest•cached•model')
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (147 > 79 characters)'
+
+options/test_options.py
+|  12| ••••••••self.parser.add_argument('--how_many',•type=int,•default=50,•help='how•many•test•images•to•run')
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (104 > 79 characters)'
+
+options/train_options.py
+|   7| ••••••••self.parser.add_argument('--display_freq',•type=int,•default=100,•help='frequency•of•showing•training•results•on•screen')
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (129 > 79 characters)'
+
+options/train_options.py
+|   8| ••••••••self.parser.add_argument('--display_single_pane_ncols',•type=int,•default=0,•help='if•positive,•display•all•images•in•a•single•visdom•web•panel•with•certain•number•of•images•per•row.')
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (192 > 79 characters)'
+
+options/train_options.py
+|   9| ••••••••self.parser.add_argument('--update_html_freq',•type=int,•default=1000,•help='frequency•of•saving•training•results•to•html')
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (131 > 79 characters)'
+
+options/train_options.py
+|  10| ••••••••self.parser.add_argument('--print_freq',•type=int,•default=100,•help='frequency•of•showing•training•results•on•console')
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (128 > 79 characters)'
+
+options/train_options.py
+|  11| ••••••••self.parser.add_argument('--save_latest_freq',•type=int,•default=5000,•help='frequency•of•saving•the•latest•results')
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (125 > 79 characters)'
+
+options/train_options.py
+|  12| ••••••••self.parser.add_argument('--save_epoch_freq',•type=int,•default=5,•help='frequency•of•saving•checkpoints•at•the•end•of•epochs')
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (135 > 79 characters)'
+
+options/train_options.py
+|  13| ••••••••self.parser.add_argument('--continue_train',•action='store_true',•help='continue•training:•load•the•latest•model')
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (122 > 79 characters)'
+
+options/train_options.py
+|  14| ••••••••self.parser.add_argument('--epoch_count',•type=int,•default=1,•help='the•starting•epoch•count,•we•save•the•model•by•<epoch_count>,•<epoch_count>+<save_latest_freq>,•...')
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (178 > 79 characters)'
+
+options/train_options.py
+|  15| ••••••••self.parser.add_argument('--phase',•type=str,•default='train',•help='train,•val,•test,•etc')
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (100 > 79 characters)'
+
+options/train_options.py
+|  16| ••••••••self.parser.add_argument('--which_epoch',•type=str,•default='latest',•help='which•epoch•to•load?•set•to•latest•to•use•latest•cached•model')
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (147 > 79 characters)'
+
+options/train_options.py
+|  17| ••••••••self.parser.add_argument('--niter',•type=int,•default=100,•help='#•of•iter•at•starting•learning•rate')
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (110 > 79 characters)'
+
+options/train_options.py
+|  18| ••••••••self.parser.add_argument('--niter_decay',•type=int,•default=100,•help='#•of•iter•to•linearly•decay•learning•rate•to•zero')
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (130 > 79 characters)'
+
+options/train_options.py
+|  19| ••••••••self.parser.add_argument('--beta1',•type=float,•default=0.5,•help='momentum•term•of•adam')
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (98 > 79 characters)'
+
+options/train_options.py
+|  20| ••••••••self.parser.add_argument('--lr',•type=float,•default=0.0002,•help='initial•learning•rate•for•adam')
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (107 > 79 characters)'
+
+options/train_options.py
+|  21| ••••••••self.parser.add_argument('--no_lsgan',•action='store_true',•help='do•*not*•use•least•square•GAN,•if•false,•use•vanilla•GAN')
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (132 > 79 characters)'
+
+options/train_options.py
+|  22| ••••••••self.parser.add_argument('--lambda_A',•type=float,•default=10.0,•help='weight•for•cycle•loss•(A•->•B•->•A)')
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (116 > 79 characters)'
+
+options/train_options.py
+|  23| ••••••••self.parser.add_argument('--lambda_B',•type=float,•default=10.0,•help='weight•for•cycle•loss•(B•->•A•->•B)')
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (116 > 79 characters)'
+
+options/train_options.py
+|  24| ••••••••self.parser.add_argument('--pool_size',•type=int,•default=50,•help='the•size•of•image•buffer•that•stores•previously•generated•images')
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (142 > 79 characters)'
+
+options/train_options.py
+|  25| ••••••••self.parser.add_argument('--no_html',•action='store_true',•help='do•not•save•intermediate•training•results•to•[opt.checkpoints_dir]/[opt.name]/web/')
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (157 > 79 characters)'
+
+options/train_options.py
+|  26| ••••••••self.parser.add_argument('--lr_policy',•type=str,•default='lambda',•help='learning•rate•policy:•lambda|step|plateau')
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (125 > 79 characters)'
+
+options/train_options.py
+|  27| ••••••••self.parser.add_argument('--lr_decay_iters',•type=int,•default=50,•help='multiply•by•a•gamma•every•lr_decay_iters•iterations')
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (134 > 79 characters)'
+
+options/train_options.py
+|  28| ••••••••self.parser.add_argument('--identity',•type=float,•default=0.5,•help='use•identity•mapping.•Setting•identity•other•than•1•has•an•effect•of•scaling•the•weight•of•the•identity•mapping•loss.•For•example,•if•the•weight•of•the•identity•loss•should•be•10•times•smaller•than•the•weight•of•the•reconstruction•loss,•please•set•optidentity•=•0.1')
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (345 > 79 characters)'
+
+models/pix2pix_model.py
+|  22| ••••••••••••••••••••••••••••••••••••••opt.which_model_netG,•opt.norm,•not•opt.no_dropout,•opt.init_type,•self.gpu_ids)
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (118 > 79 characters)'
+
+models/pix2pix_model.py
+|  25| ••••••••••••self.netD•=•networks.define_D(opt.input_nc•+•opt.output_nc,•opt.ndf,
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (80 > 79 characters)'
+
+models/pix2pix_model.py
+|  27| ••••••••••••••••••••••••••••••••••••••••••opt.n_layers_D,•opt.norm,•use_sigmoid,•opt.init_type,•self.gpu_ids)
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (109 > 79 characters)'
+
+models/pix2pix_model.py
+|  37| ••••••••••••self.criterionGAN•=•networks.GANLoss(use_lsgan=not•opt.no_lsgan,•tensor=self.Tensor)
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (96 > 79 characters)'
+
+models/pix2pix_model.py
+|  44| ••••••••••••••••••••••••••••••••••••••••••••••••lr=opt.lr,•betas=(opt.beta1,•0.999))
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (84 > 79 characters)'
+
+models/pix2pix_model.py
+|  46| ••••••••••••••••••••••••••••••••••••••••••••••••lr=opt.lr,•betas=(opt.beta1,•0.999))
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (84 > 79 characters)'
+
+models/pix2pix_model.py
+|  87| ••••••••fake_AB•=•self.fake_AB_pool.query(torch.cat((self.real_A,•self.fake_B),•1).data)
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (88 > 79 characters)'
+
+models/pix2pix_model.py
+| 108| ••••••••self.loss_G_L1•=•self.criterionL1(self.fake_B,•self.real_B)•*•self.opt.lambda_A
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (87 > 79 characters)'
+
+models/pix2pix_model.py
+| 136| ••••••••return•OrderedDict([('real_A',•real_A),•('fake_B',•fake_B),•('real_B',•real_B)])
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (88 > 79 characters)'
+
+util/visualizer.py
+|  28| ••••••••self.log_name•=•os.path.join(opt.checkpoints_dir,•opt.name,•'loss_log.txt')
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (83 > 79 characters)'
+
+util/visualizer.py
+|  31| ••••••••••••log_file.write('================•Training•Loss•(%s)•================\n'•%•now)
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (90 > 79 characters)'
+
+util/visualizer.py
+|  43| ••••••••••••••••••••••••table•{border-collapse:•separate;•border-spacing:4px;•white-space:nowrap;•text-align:center}
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (116 > 79 characters)'
+
+util/visualizer.py
+|  44| ••••••••••••••••••••••••table•td•{width:•%dpx;•height:•%dpx;•padding:•4px;•outline:•4px•solid•black}
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (100 > 79 characters)'
+
+util/visualizer.py
+|  59| ••••••••••••••••white_image•=•np.ones_like(image_numpy.transpose([2,•0,•1]))*255
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (80 > 79 characters)'
+
+util/visualizer.py
+|  75| ••••••••••••••••••••self.vis.image(image_numpy.transpose([2,•0,•1]),•opts=dict(title=label),
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (92 > 79 characters)'
+
+util/visualizer.py
+|  79| ••••••••if•self.use_html•and•(save_result•or•not•self.saved):••#•save•images•to•a•html•file
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (91 > 79 characters)'
+
+util/visualizer.py
+|  82| ••••••••••••••••img_path•=•os.path.join(self.img_dir,•'epoch%.3d_%s.png'•%•(epoch,•label))
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (90 > 79 characters)'
+
+util/visualizer.py
+|  85| ••••••••••••webpage•=•html.HTML(self.web_dir,•'Experiment•name•=•%s'•%•self.name,•reflesh=1)
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (92 > 79 characters)'
+
+util/visualizer.py
+| 105| ••••••••self.plot_data['Y'].append([errors[k]•for•k•in•self.plot_data['legend']])
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (81 > 79 characters)'
+
+util/visualizer.py
+| 107| ••••••••••••X=np.stack([np.array(self.plot_data['X'])]•*•len(self.plot_data['legend']),•1),
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (91 > 79 characters)'
+
+data/base_data_loader.py
+|   5| ••••
+|    | [NORMAL] PycodestyleBear (W293):
+|    | W293 blank line contains whitespace'
+
+data/base_data_loader.py
+|  13| ••••••••
+|    | [NORMAL] PycodestyleBear (W293):
+|    | W293 blank line contains whitespace'
+
+data/base_data_loader.py
+|  14| ••••••••
+|    | [NORMAL] PycodestyleBear (W293):
+|    | W293 blank line contains whitespace'
+
+data/base_data_loader.py
+|  14| ••••••••
+|    | [NORMAL] PycodestyleBear (W391):
+|    | W391 blank line at end of file'
+
+datasets/combine_A_and_B.py
+|   7| parser.add_argument('--fold_A',•dest='fold_A',•help='input•directory•for•image•A',•type=str,•default='../dataset/50kshoes_edges')
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (129 > 79 characters)'
+
+datasets/combine_A_and_B.py
+|   8| parser.add_argument('--fold_B',•dest='fold_B',•help='input•directory•for•image•B',•type=str,•default='../dataset/50kshoes_jpg')
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (127 > 79 characters)'
+
+datasets/combine_A_and_B.py
+|   9| parser.add_argument('--fold_AB',•dest='fold_AB',•help='output•directory',•type=str,•default='../dataset/test_AB')
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (113 > 79 characters)'
+
+datasets/combine_A_and_B.py
+|  10| parser.add_argument('--num_imgs',•dest='num_imgs',•help='number•of•images',type=int,•default=1000000)
+|    | [NORMAL] PycodestyleBear (E231):
+|    | E231 missing whitespace after ',''
+
+datasets/combine_A_and_B.py
+|  10| parser.add_argument('--num_imgs',•dest='num_imgs',•help='number•of•images',type=int,•default=1000000)
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (101 > 79 characters)'
+
+datasets/combine_A_and_B.py
+|  11| parser.add_argument('--use_AB',•dest='use_AB',•help='if•true:•(0001_A,•0001_B)•to•(0001_AB)',action='store_true')
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (113 > 79 characters)'
+
+datasets/combine_A_and_B.py
+|  11| parser.add_argument('--use_AB',•dest='use_AB',•help='if•true:•(0001_A,•0001_B)•to•(0001_AB)',action='store_true')
+|    | [NORMAL] PycodestyleBear (E231):
+|    | E231 missing whitespace after ',''
+
+datasets/combine_A_and_B.py
+|  43| ••••••••••••••••name_AB•=•name_AB.replace('_A.',•'.')•#•remove•_A
+|    | [NORMAL] PycodestyleBear (E261):
+|    | E261 at least two spaces before inline comment'
+
+util/get_data.py
+|  25| ••••••••>>>•new_data_path•=•gd.get(save_path='./datasets')••#•options•will•be•displayed.
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (88 > 79 characters)'
+
+util/get_data.py
+|  31| ••••••••••••'pix2pix':•'https://people.eecs.berkeley.edu/~tinghuiz/projects/pix2pix/datasets',
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (94 > 79 characters)'
+
+util/get_data.py
+|  32| ••••••••••••'cyclegan':•'https://people.eecs.berkeley.edu/~taesung_park/CycleGAN/datasets'
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (90 > 79 characters)'
+
+train.py
+|  31| ••••••••••••visualizer.display_current_results(model.get_current_visuals(),•epoch,•save_result)
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (95 > 79 characters)'
+
+train.py
+|  38| ••••••••••••••••visualizer.plot_current_errors(epoch,•float(epoch_iter)/dataset_size,•opt,•errors)
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (98 > 79 characters)'
+
+models/networks.py
+|  72| ••••••••raise•NotImplementedError('initialization•method•[%s]•is•not•implemented'•%•init_type)
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (94 > 79 characters)'
+
+models/networks.py
+|  83| ••••••••raise•NotImplementedError('normalization•layer•[%s]•is•not•found'•%•norm_type)
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (86 > 79 characters)'
+
+models/networks.py
+|  90| ••••••••••••lr_l•=•1.0•-•max(0,•epoch•+•1•+•opt.epoch_count•-•opt.niter)•/•float(opt.niter_decay•+•1)
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (101 > 79 characters)'
+
+models/networks.py
+|  94| ••••••••scheduler•=•lr_scheduler.StepLR(optimizer,•step_size=opt.lr_decay_iters,•gamma=0.1)
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (91 > 79 characters)'
+
+models/networks.py
+|  96| ••••••••scheduler•=•lr_scheduler.ReduceLROnPlateau(optimizer,•mode='min',•factor=0.2,•threshold=0.01,•patience=5)
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (113 > 79 characters)'
+
+models/networks.py
+|  98| ••••••••return•NotImplementedError('learning•rate•policy•[%s]•is•not•implemented',•opt.lr_policy)
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (97 > 79 characters)'
+
+models/networks.py
+| 102| def•define_G(input_nc,•output_nc,•ngf,•which_model_netG,•norm='batch',•use_dropout=False,•init_type='normal',•gpu_ids=[]):
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (122 > 79 characters)'
+
+models/networks.py
+| 111| ••••••••netG•=•ResnetGenerator(input_nc,•output_nc,•ngf,•norm_layer=norm_layer,•use_dropout=use_dropout,•n_blocks=9,•gpu_ids=gpu_ids)
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (133 > 79 characters)'
+
+models/networks.py
+| 113| ••••••••netG•=•ResnetGenerator(input_nc,•output_nc,•ngf,•norm_layer=norm_layer,•use_dropout=use_dropout,•n_blocks=6,•gpu_ids=gpu_ids)
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (133 > 79 characters)'
+
+models/networks.py
+| 115| ••••••••netG•=•UnetGenerator(input_nc,•output_nc,•7,•ngf,•norm_layer=norm_layer,•use_dropout=use_dropout,•gpu_ids=gpu_ids)
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (122 > 79 characters)'
+
+models/networks.py
+| 117| ••••••••netG•=•UnetGenerator(input_nc,•output_nc,•8,•ngf,•norm_layer=norm_layer,•use_dropout=use_dropout,•gpu_ids=gpu_ids)
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (122 > 79 characters)'
+
+models/networks.py
+| 119| ••••••••raise•NotImplementedError('Generator•model•name•[%s]•is•not•recognized'•%•which_model_netG)
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (99 > 79 characters)'
+
+models/networks.py
+| 127| •••••••••••••n_layers_D=3,•norm='batch',•use_sigmoid=False,•init_type='normal',•gpu_ids=[]):
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (92 > 79 characters)'
+
+models/networks.py
+| 135| ••••••••netD•=•NLayerDiscriminator(input_nc,•ndf,•n_layers=3,•norm_layer=norm_layer,•use_sigmoid=use_sigmoid,•gpu_ids=gpu_ids)
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (126 > 79 characters)'
+
+models/networks.py
+| 137| ••••••••netD•=•NLayerDiscriminator(input_nc,•ndf,•n_layers_D,•norm_layer=norm_layer,•use_sigmoid=use_sigmoid,•gpu_ids=gpu_ids)
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (126 > 79 characters)'
+
+models/networks.py
+| 139| ••••••••netD•=•PixelDiscriminator(input_nc,•ndf,•norm_layer=norm_layer,•use_sigmoid=use_sigmoid,•gpu_ids=gpu_ids)
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (113 > 79 characters)'
+
+models/networks.py
+| 141| ••••••••raise•NotImplementedError('Discriminator•model•name•[%s]•is•not•recognized'•%
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (85 > 79 characters)'
+
+models/networks.py
+| 167| ••••def•__init__(self,•use_lsgan=True,•target_real_label=1.0,•target_fake_label=0.0,
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (84 > 79 characters)'
+
+models/networks.py
+| 187| ••••••••••••••••self.real_label_var•=•Variable(real_tensor,•requires_grad=False)
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (80 > 79 characters)'
+
+models/networks.py
+| 194| ••••••••••••••••self.fake_label_var•=•Variable(fake_tensor,•requires_grad=False)
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (80 > 79 characters)'
+
+models/networks.py
+| 208| ••••def•__init__(self,•input_nc,•output_nc,•ngf=64,•norm_layer=nn.BatchNorm2d,•use_dropout=False,•n_blocks=6,•gpu_ids=[],•padding_type='reflect'):
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (146 > 79 characters)'
+
+models/networks.py
+| 236| ••••••••••••model•+=•[ResnetBlock(ngf•*•mult,•padding_type=padding_type,•norm_layer=norm_layer,•use_dropout=use_dropout,•use_bias=use_bias)]
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (140 > 79 characters)'
+
+models/networks.py
+| 263| ••••••••self.conv_block•=•self.build_conv_block(dim,•padding_type,•norm_layer,•use_dropout,•use_bias)
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (101 > 79 characters)'
+
+models/networks.py
+| 265| ••••def•build_conv_block(self,•dim,•padding_type,•norm_layer,•use_dropout,•use_bias):
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (85 > 79 characters)'
+
+models/networks.py
+| 275| ••••••••••••raise•NotImplementedError('padding•[%s]•is•not•implemented'•%•padding_type)
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (87 > 79 characters)'
+
+models/networks.py
+| 277| ••••••••conv_block•+=•[nn.Conv2d(dim,•dim,•kernel_size=3,•padding=p,•bias=use_bias),
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (84 > 79 characters)'
+
+models/networks.py
+| 291| ••••••••••••raise•NotImplementedError('padding•[%s]•is•not•implemented'•%•padding_type)
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (87 > 79 characters)'
+
+models/networks.py
+| 292| ••••••••conv_block•+=•[nn.Conv2d(dim,•dim,•kernel_size=3,•padding=p,•bias=use_bias),
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (84 > 79 characters)'
+
+models/networks.py
+| 313| ••••••••unet_block•=•UnetSkipConnectionBlock(ngf•*•8,•ngf•*•8,•input_nc=None,•submodule=None,•norm_layer=norm_layer,•innermost=True)
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (132 > 79 characters)'
+
+models/networks.py
+| 315| ••••••••••••unet_block•=•UnetSkipConnectionBlock(ngf•*•8,•ngf•*•8,•input_nc=None,•submodule=unet_block,•norm_layer=norm_layer,•use_dropout=use_dropout)
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (151 > 79 characters)'
+
+models/networks.py
+| 316| ••••••••unet_block•=•UnetSkipConnectionBlock(ngf•*•4,•ngf•*•8,•input_nc=None,•submodule=unet_block,•norm_layer=norm_layer)
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (122 > 79 characters)'
+
+models/networks.py
+| 317| ••••••••unet_block•=•UnetSkipConnectionBlock(ngf•*•2,•ngf•*•4,•input_nc=None,•submodule=unet_block,•norm_layer=norm_layer)
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (122 > 79 characters)'
+
+models/networks.py
+| 318| ••••••••unet_block•=•UnetSkipConnectionBlock(ngf,•ngf•*•2,•input_nc=None,•submodule=unet_block,•norm_layer=norm_layer)
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (118 > 79 characters)'
+
+models/networks.py
+| 319| ••••••••unet_block•=•UnetSkipConnectionBlock(output_nc,•ngf,•input_nc=input_nc,•submodule=unet_block,•outermost=True,•norm_layer=norm_layer)
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (140 > 79 characters)'
+
+models/networks.py
+| 335| •••••••••••••••••submodule=None,•outermost=False,•innermost=False,•norm_layer=nn.BatchNorm2d,•use_dropout=False):
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (113 > 79 characters)'
+
+models/networks.py
+| 388| ••••def•__init__(self,•input_nc,•ndf=64,•n_layers=3,•norm_layer=nn.BatchNorm2d,•use_sigmoid=False,•gpu_ids=[]):
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (111 > 79 characters)'
+
+models/networks.py
+| 410| ••••••••••••••••••••••••••kernel_size=kw,•stride=2,•padding=padw,•bias=use_bias),
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (81 > 79 characters)'
+
+models/networks.py
+| 424| ••••••••sequence•+=•[nn.Conv2d(ndf•*•nf_mult,•1,•kernel_size=kw,•stride=1,•padding=padw)]
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (89 > 79 characters)'
+
+models/networks.py
+| 432| ••••••••if•len(self.gpu_ids)•and•isinstance(input.data,•torch.cuda.FloatTensor):
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (80 > 79 characters)'
+
+models/networks.py
+| 437| class•PixelDiscriminator(nn.Module):
+|    | [NORMAL] PycodestyleBear (E302):
+|    | E302 expected 2 blank lines, found 1'
+
+models/networks.py
+| 438| ••••def•__init__(self,•input_nc,•ndf=64,•norm_layer=nn.BatchNorm2d,•use_sigmoid=False,•gpu_ids=[]):
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (99 > 79 characters)'
+
+models/networks.py
+| 445| ••••••••••••
+|    | [NORMAL] PycodestyleBear (W293):
+|    | W293 blank line contains whitespace'
+
+models/networks.py
+| 449| ••••••••••••nn.Conv2d(ndf,•ndf•*•2,•kernel_size=1,•stride=1,•padding=0,•bias=use_bias),
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (87 > 79 characters)'
+
+models/networks.py
+| 452| ••••••••••••nn.Conv2d(ndf•*•2,•1,•kernel_size=1,•stride=1,•padding=0,•bias=use_bias)]
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (85 > 79 characters)'
+
+models/networks.py
+| 460| ••••••••if•len(self.gpu_ids)•and•isinstance(input.data,•torch.cuda.FloatTensor):
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (80 > 79 characters)'
+
+models/networks.py
+| 464| 
+|    | [NORMAL] PycodestyleBear (W391):
+|    | W391 blank line at end of file'
+
+models/cycle_gan_model.py
+|  29| ••••••••••••••••••••••••••••••••••••••••opt.ngf,•opt.which_model_netG,•opt.norm,•not•opt.no_dropout,•opt.init_type,•self.gpu_ids)
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (129 > 79 characters)'
+
+models/cycle_gan_model.py
+|  31| ••••••••••••••••••••••••••••••••••••••••opt.ngf,•opt.which_model_netG,•opt.norm,•not•opt.no_dropout,•opt.init_type,•self.gpu_ids)
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (129 > 79 characters)'
+
+models/cycle_gan_model.py
+|  37| ••••••••••••••••••••••••••••••••••••••••••••opt.n_layers_D,•opt.norm,•use_sigmoid,•opt.init_type,•self.gpu_ids)
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (111 > 79 characters)'
+
+models/cycle_gan_model.py
+|  40| ••••••••••••••••••••••••••••••••••••••••••••opt.n_layers_D,•opt.norm,•use_sigmoid,•opt.init_type,•self.gpu_ids)
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (111 > 79 characters)'
+
+models/cycle_gan_model.py
+|  54| ••••••••••••self.criterionGAN•=•networks.GANLoss(use_lsgan=not•opt.no_lsgan,•tensor=self.Tensor)
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (96 > 79 characters)'
+
+models/cycle_gan_model.py
+|  58| ••••••••••••self.optimizer_G•=•torch.optim.Adam(itertools.chain(self.netG_A.parameters(),•self.netG_B.parameters()),
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (116 > 79 characters)'
+
+models/cycle_gan_model.py
+|  59| ••••••••••••••••••••••••••••••••••••••••••••••••lr=opt.lr,•betas=(opt.beta1,•0.999))
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (84 > 79 characters)'
+
+models/cycle_gan_model.py
+|  60| ••••••••••••self.optimizer_D_A•=•torch.optim.Adam(self.netD_A.parameters(),•lr=opt.lr,•betas=(opt.beta1,•0.999))
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (112 > 79 characters)'
+
+models/cycle_gan_model.py
+|  61| ••••••••••••self.optimizer_D_B•=•torch.optim.Adam(self.netD_B.parameters(),•lr=opt.lr,•betas=(opt.beta1,•0.999))
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (112 > 79 characters)'
+
+models/cycle_gan_model.py
+| 139| ••••••••••••loss_idt_A•=•self.criterionIdt(idt_A,•self.real_B)•*•lambda_B•*•lambda_idt
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (86 > 79 characters)'
+
+models/cycle_gan_model.py
+| 142| ••••••••••••loss_idt_B•=•self.criterionIdt(idt_B,•self.real_A)•*•lambda_A•*•lambda_idt
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (86 > 79 characters)'
+
+models/cycle_gan_model.py
+| 172| ••••••••loss_G•=•loss_G_A•+•loss_G_B•+•loss_cycle_A•+•loss_cycle_B•+•loss_idt_A•+•loss_idt_B
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (92 > 79 characters)'
+
+models/cycle_gan_model.py
+| 202| ••••••••ret_errors•=•OrderedDict([('D_A',•self.loss_D_A),•('G_A',•self.loss_G_A),•('Cyc_A',•self.loss_cycle_A),
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (111 > 79 characters)'
+
+models/cycle_gan_model.py
+| 203| •••••••••••••••••••••••••••••••••('D_B',•self.loss_D_B),•('G_B',•self.loss_G_B),•('Cyc_B',••self.loss_cycle_B)])
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (112 > 79 characters)'
+
+models/cycle_gan_model.py
+| 216| ••••••••ret_visuals•=•OrderedDict([('real_A',•real_A),•('fake_B',•fake_B),•('rec_A',•rec_A),
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (92 > 79 characters)'
+
+models/cycle_gan_model.py
+| 217| •••••••••••••••••••••••••••••••••••('real_B',•real_B),•('fake_A',•fake_A),•('rec_B',•rec_B)])
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (93 > 79 characters)'
+
+data/unaligned_dataset.py
+|   9| class•UnalignedDataset(BaseDataset):
+|    | [NORMAL] PycodestyleBear (E302):
+|    | E302 expected 2 blank lines, found 1'
+
+util/util.py
+|  46| ••••••••print('mean•=•%3.3f,•min•=•%3.3f,•max•=•%3.3f,•median•=•%3.3f,•std=%3.3f'•%•(
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (85 > 79 characters)'
+
+options/base_options.py
+|   9| ••••••••self.parser•=•argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (101 > 79 characters)'
+
+options/base_options.py
+|  13| ••••••••self.parser.add_argument('--dataroot',•required=True,•help='path•to•images•(should•have•subfolders•trainA,•trainB,•valA,•valB,•etc)')
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (141 > 79 characters)'
+
+options/base_options.py
+|  14| ••••••••self.parser.add_argument('--batchSize',•type=int,•default=1,•help='input•batch•size')
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (93 > 79 characters)'
+
+options/base_options.py
+|  15| ••••••••self.parser.add_argument('--loadSize',•type=int,•default=286,•help='scale•images•to•this•size')
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (103 > 79 characters)'
+
+options/base_options.py
+|  16| ••••••••self.parser.add_argument('--fineSize',•type=int,•default=256,•help='then•crop•to•this•size')
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (100 > 79 characters)'
+
+options/base_options.py
+|  17| ••••••••self.parser.add_argument('--input_nc',•type=int,•default=3,•help='#•of•input•image•channels')
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (101 > 79 characters)'
+
+options/base_options.py
+|  18| ••••••••self.parser.add_argument('--output_nc',•type=int,•default=3,•help='#•of•output•image•channels')
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (103 > 79 characters)'
+
+options/base_options.py
+|  19| ••••••••self.parser.add_argument('--ngf',•type=int,•default=64,•help='#•of•gen•filters•in•first•conv•layer')
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (108 > 79 characters)'
+
+options/base_options.py
+|  20| ••••••••self.parser.add_argument('--ndf',•type=int,•default=64,•help='#•of•discrim•filters•in•first•conv•layer')
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (112 > 79 characters)'
+
+options/base_options.py
+|  21| ••••••••self.parser.add_argument('--which_model_netD',•type=str,•default='basic',•help='selects•model•to•use•for•netD')
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (119 > 79 characters)'
+
+options/base_options.py
+|  22| ••••••••self.parser.add_argument('--which_model_netG',•type=str,•default='resnet_9blocks',•help='selects•model•to•use•for•netG')
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (128 > 79 characters)'
+
+options/base_options.py
+|  23| ••••••••self.parser.add_argument('--n_layers_D',•type=int,•default=3,•help='only•used•if•which_model_netD==n_layers')
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (117 > 79 characters)'
+
+options/base_options.py
+|  24| ••••••••self.parser.add_argument('--gpu_ids',•type=str,•default='0',•help='gpu•ids:•e.g.•0••0,1,2,•0,2.•use•-1•for•CPU')
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (120 > 79 characters)'
+
+options/base_options.py
+|  25| ••••••••self.parser.add_argument('--name',•type=str,•default='experiment_name',•help='name•of•the•experiment.•It•decides•where•to•store•samples•and•models')
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (156 > 79 characters)'
+
+options/base_options.py
+|  26| ••••••••self.parser.add_argument('--dataset_mode',•type=str,•default='unaligned',•help='chooses•how•datasets•are•loaded.•[unaligned•|•aligned•|•single]')
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (153 > 79 characters)'
+
+options/base_options.py
+|  28| •••••••••••••••••••••••••••••••••help='chooses•which•model•to•use.•cycle_gan,•pix2pix,•test')
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (93 > 79 characters)'
+
+options/base_options.py
+|  29| ••••••••self.parser.add_argument('--which_direction',•type=str,•default='AtoB',•help='AtoB•or•BtoA')
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (100 > 79 characters)'
+
+options/base_options.py
+|  30| ••••••••self.parser.add_argument('--nThreads',•default=2,•type=int,•help='#•threads•for•loading•data')
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (102 > 79 characters)'
+
+options/base_options.py
+|  31| ••••••••self.parser.add_argument('--checkpoints_dir',•type=str,•default='./checkpoints',•help='models•are•saved•here')
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (118 > 79 characters)'
+
+options/base_options.py
+|  32| ••••••••self.parser.add_argument('--norm',•type=str,•default='instance',•help='instance•normalization•or•batch•normalization')
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (126 > 79 characters)'
+
+options/base_options.py
+|  33| ••••••••self.parser.add_argument('--serial_batches',•action='store_true',•help='if•true,•takes•images•in•order•to•make•batches,•otherwise•takes•them•randomly')
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (159 > 79 characters)'
+
+options/base_options.py
+|  34| ••••••••self.parser.add_argument('--display_winsize',•type=int,•default=256,••help='display•window•size')
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (105 > 79 characters)'
+
+options/base_options.py
+|  35| ••••••••self.parser.add_argument('--display_id',•type=int,•default=1,•help='window•id•of•the•web•display')
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (106 > 79 characters)'
+
+options/base_options.py
+|  36| ••••••••self.parser.add_argument('--display_port',•type=int,•default=8097,•help='visdom•port•of•the•web•display')
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (113 > 79 characters)'
+
+options/base_options.py
+|  37| ••••••••self.parser.add_argument('--no_dropout',•action='store_true',•help='no•dropout•for•the•generator')
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (106 > 79 characters)'
+
+options/base_options.py
+|  38| ••••••••self.parser.add_argument('--max_dataset_size',•type=int,•default=float("inf"),•help='Maximum•number•of•samples•allowed•per•dataset.•If•the•dataset•directory•contains•more•than•max_dataset_size,•only•a•subset•is•loaded.')
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (228 > 79 characters)'
+
+options/base_options.py
+|  39| ••••••••self.parser.add_argument('--resize_or_crop',•type=str,•default='resize_and_crop',•help='scaling•and•cropping•of•images•at•load•time•[resize_and_crop|crop|scale_width|scale_width_and_crop]')
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (197 > 79 characters)'
+
+options/base_options.py
+|  40| ••••••••self.parser.add_argument('--no_flip',•action='store_true',•help='if•specified,•do•not•flip•the•images•for•data•augmentation')
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (133 > 79 characters)'
+
+options/base_options.py
+|  41| ••••••••self.parser.add_argument('--init_type',•type=str,•default='normal',•help='network•initialization•[normal|xavier|kaiming|orthogonal]')
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (141 > 79 characters)'
+
+util/html.py
+|  38| ••••••••••••••••••••with•td(style="word-wrap:•break-word;",•halign="center",•valign="top"):
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (91 > 79 characters)'
+
+util/html.py
+|  41| ••••••••••••••••••••••••••••••••img(style="width:%dpx"•%•width,•src=os.path.join('images',•im))
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (95 > 79 characters)'
+
+data/aligned_dataset.py
+|  21| ••••••••AB•=•AB.resize((self.opt.loadSize•*•2,•self.opt.loadSize),•Image.BICUBIC)
+|    | [NORMAL] PycodestyleBear (E501):
+|    | E501 line too long (81 > 79 characters)'
+Executing section yaml...
